{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Recordemos que una pequeña red neuronal con una sola capa lineal seguida de una función sigmoidea es un clasificador binario. Actúa igual que una regresión logística.\n",
    "\n",
    "En este ejercicio, practicarás la construcción de esta pequeña red y la interpretación de la salida del clasificador.\n",
    "\n",
    "Los paquetes torch y torch.nn ya han sido importados."
   ],
   "id": "4c33e811c8339458"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Instrucciones 1/2\n",
    "50 XP\n",
    "1\n",
    "2\n",
    "Crear una red neuronal que tome un tensor de dimensiones 1x8 como entrada, y devuelva una salida de la forma correcta para la clasificación binaria.\n",
    "Pasa la salida de la capa lineal a una sigmoidea, que toma y devuelve un único float."
   ],
   "id": "7cfa733a0cc66b3a"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-06-12T21:09:19.728427Z",
     "start_time": "2024-06-12T21:09:17.781401Z"
    }
   },
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "input_tensor = torch.Tensor([[3, 4, 6, 2, 3, 6, 8, 9]])\n",
    "\n",
    "# Implement a small neural network for binary classification\n",
    "model = nn.Sequential(\n",
    "  nn.Linear(8, 1), # Linear layer from 8 to 1 neurons\n",
    "  nn.Sigmoid() # Sigmoid function\n",
    ")\n",
    "\n",
    "output = model(input_tensor)\n",
    "print(output)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.9840]], grad_fn=<SigmoidBackward0>)\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "De la regresión a la clasificación multiclase\n",
    "Recordemos que los modelos que hemos visto para la clasificación binaria, la clasificación multiclase y la regresión han sido todos similares, salvo algunos retoques en el modelo.\n",
    "\n",
    "En este ejercicio, empezarás construyendo un modelo de regresión y, a continuación, ajustarás el modelo para realizar una clasificación multiclase."
   ],
   "id": "7368ac3b4cf8d58"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Instrucciones 1/2\n",
    "50 XP\n",
    "1\n",
    "Crea una red neuronal con exactamente cuatro capas lineales, que toma el tensor de entrada como entrada, y da como salida un valor de regresión, usando las formas que quieras para las capas ocultas."
   ],
   "id": "5b42203bce87aaa5"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-12T21:09:22.156894Z",
     "start_time": "2024-06-12T21:09:22.152153Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "input_tensor = torch.Tensor([[3, 4, 6, 7, 10, 12, 2, 3, 6, 8, 9]])\n",
    "\n",
    "# Implement a neural network with exactly four linear layers\n",
    "model = nn.Sequential(\n",
    "    nn.Linear(11, 8),\n",
    "    nn.Linear(8, 4),\n",
    "    nn.Linear(4, 2),\n",
    "    nn.Linear(2, 1)\n",
    "    )\n",
    "\n",
    "output = model(input_tensor)\n",
    "print(output)"
   ],
   "id": "3ae471df8910ad4b",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.7993]], grad_fn=<AddmmBackward0>)\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Se proporciona una red neuronal similar a la que acaba de construir, que contiene cuatro capas lineales; actualice esta red para realizar una clasificación multiclase con cuatro salidas.",
   "id": "87cd022262477387"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-12T21:09:23.161502Z",
     "start_time": "2024-06-12T21:09:23.156437Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "\n",
    "input_tensor = torch.Tensor([[3, 4, 6, 7, 10, 12, 2, 3, 6, 8, 9]])\n",
    "\n",
    "# Update network below to perform a multi-class classification with four labels\n",
    "model = nn.Sequential(\n",
    "    nn.Linear(11, 20), # 20 output neurons\n",
    "    nn.Linear(20, 12), # 12 output neurons\n",
    "    nn.Linear(12, 6), # 6 output neurons\n",
    "    nn.Linear(6, 4),  # 4 output neurons\n",
    "    nn.Softmax(dim=1) # Softmax function\n",
    ")\n",
    "\n",
    "output = model(input_tensor)\n",
    "print(output)"
   ],
   "id": "5da4446155aac35d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.1649, 0.2500, 0.5186, 0.0665]], grad_fn=<SoftmaxBackward0>)\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Funciones de perdida para evaluar las predicciones\n",
    "\n",
    "En este ejercicio, se le proporciona un tensor de predicciones y un tensor de etiquetas, y se le pide que calcule la pérdida de entropía cruzada.\n",
    "\n",
    "Recuerde que la entropía cruzada se calcula como la suma de las etiquetas multiplicadas por el logaritmo de las predicciones, todo ello negado."
   ],
   "id": "9168a200a33dfbb"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Creación de etiquetas codificadas en un solo paso\n",
    "La codificación one-hot es una técnica que convierte una única etiqueta entera en un vector de N elementos, donde N es el número de clases de su conjunto de datos. Este vector sólo contiene ceros y unos. En este ejercicio, crearás el vector codificado de un punto de la etiqueta y proporcionada.\n",
    "\n",
    "Practicarás cómo hacerlo manualmente y luego te facilitarás la vida aprovechando la ayuda de PyTorch. Su conjunto de datos contiene tres clases.\n",
    "\n",
    "NumPy ya está importado como np, y torch.nn.functional como F. También se importa el paquete torch.\n",
    "\n",
    "Instrucciones\n",
    "100 XP\n",
    "Cree manualmente un vector codificado de un solo golpe de la etiqueta de verdad del terreno y rellenando el array NumPy proporcionado.\n",
    "Crear un vector codificado de un solo golpe de la etiqueta de la verdad del suelo y utilizando PyTorch."
   ],
   "id": "3133e305bde316c2"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-12T21:09:24.665595Z",
     "start_time": "2024-06-12T21:09:24.660278Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "\n",
    "y = 1 # La y es la etiqueta de la verdad del suelo\n",
    "num_classes = 3 # Número de clases\n",
    "\n",
    "# Creamos un vector one-hot manualmente\n",
    "one_hot_numpy = np.array([0, 1, 0])\n",
    "\n",
    "# Creamos un vector one-hot con PyTorch\n",
    "one_hot_pytorch = F.one_hot(torch.tensor([y]), num_classes=num_classes)\n",
    "\n",
    "print(one_hot_pytorch)"
   ],
   "id": "a663a8bf1bc57584",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0, 1, 0]])\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Cálculo de la pérdida de entropía cruzada\n",
    "La pérdida de entropía cruzada es la más utilizada para los problemas de clasificación. En este ejercicio, crearás entradas y calcularás la pérdida de entropía cruzada en PyTorch. Se le proporciona la etiqueta verdadera y y un vector de scores predicho por su modelo.\n",
    "\n",
    "Empezarás por crear un vector codificado de una sola vez de la etiqueta de verdad del terreno y, que es un paso necesario para comparar y con las puntuaciones predichas por tu modelo. A continuación, crearás una función de pérdida de entropía cruzada. Por último, se llamará a la función de pérdida, que toma como entradas scores (predicciones del modelo antes de la función softmax final) y la etiqueta de verdad fundamental codificada en un punto. Emite un único flotador, la pérdida de esa muestra.\n",
    "\n",
    "torch``torch.nn como nn, y torch.nn.functional como F ya se han importado para usted."
   ],
   "id": "8a55133a8673bc8e"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Instrucciones 1/3\n",
    "35 XP\n",
    "1\n",
    "2\n",
    "3\n",
    "Crea el vector codificado de una sola vez de la etiqueta de verdad básica y y asígnalo a one_hot_label."
   ],
   "id": "c475797623be7cd1"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-12T21:09:26.383447Z",
     "start_time": "2024-06-12T21:09:26.379436Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "y = [2] # La y es la etiqueta de la verdad del suelo\n",
    "scores = torch.tensor([[0.1, 6.0, -2.0, 3.2]]) # Las puntuaciones son las predicciones del modelo antes de la función softmax final\n",
    "\n",
    "# Create a one-hot encoded vector of the ground truth label\n",
    "one_hot_label = F.one_hot(torch.tensor(y), num_classes=4)\n",
    "\n",
    "print(one_hot_label)"
   ],
   "id": "d260c5d51e8e959b",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0, 0, 1, 0]])\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Cree la función de pérdida de entropía cruzada y guárdela como criterion.",
   "id": "552d0ce250d47073"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-12T21:09:50.822677Z",
     "start_time": "2024-06-12T21:09:50.815896Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "y = [2]\n",
    "scores = torch.tensor([[0.1, 6.0, -2.0, 3.2]])\n",
    "\n",
    "# Create a one-hot encoded vector of the label y\n",
    "one_hot_label = F.one_hot(torch.tensor(y), num_classes = scores.shape[1])\n",
    "\n",
    "# Create the cross entropy loss function\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "print(criterion(scores, torch.tensor(y)))"
   ],
   "id": "b0f6873afec4df75",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(8.0619)\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Calcule la pérdida de entropía cruzada utilizando el vector one_hot_label y el vector scores, llamando al loss_function que ha creado.\n",
    "\n",
    "Did you correctly specify the first argument? Expected scores.double(), but got scores."
   ],
   "id": "7abf1ab1b1131090"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-12T21:12:57.886173Z",
     "start_time": "2024-06-12T21:12:57.876277Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "y = [2] # La y es la etiqueta de la verdad del suelo. La verdad del suelo es la etiqueta correcta\n",
    "scores = torch.tensor([[0.1, 6.0, -2.0, 3.2]]) # Las puntuaciones son las predicciones del modelo antes de la función softmax final\n",
    "\n",
    "# Create a one-hot encoded vector of the label y\n",
    "one_hot_label = F.one_hot(torch.tensor(y), scores.shape[1]) # 4 clases\n",
    "\n",
    "# Create the cross entropy loss function\n",
    "criterion = nn.CrossEntropyLoss() # La función de pérdida de entropía cruzada\n",
    "\n",
    "# Calculate the cross entropy loss scores.double().\n",
    "loss = criterion(scores.double(), one_hot_label.double())\n",
    "print(loss)"
   ],
   "id": "68d62b4aa4fdd337",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(8.0619, dtype=torch.float64)\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Estimación de una muestra\n",
    "En ejercicios anteriores, utilizaste capas lineales para construir redes.\n",
    "\n",
    "Recordemos que la operación realizada por nn.Linear() consiste en tomar una entrada \n",
    " y aplicar la transformación \n",
    ",donde \n",
    " y \n",
    " son dos tensores (denominados peso y sesgo).\n",
    "\n",
    "Una parte fundamental del entrenamiento de los modelos PyTorch consiste en calcular los gradientes de los tensores de peso y sesgo con respecto a una función de pérdida."
   ],
   "id": "d5b8947ceee7e67c"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "\n",
    "En este ejercicio, calculará gradientes de tensor de peso y sesgo utilizando pérdida de entropía cruzada y una muestra de datos.\n",
    "\n",
    "Se prueban los siguientes tensores:\n",
    "\n",
    "weight: un tensor \n",
    "-elemento\n",
    "biasun tensor de \n",
    " elementos\n",
    "preds: un tensor \n",
    "-elemento que contiene las predicciones del modelo\n",
    "target: un tensor codificado de un solo elemento \n",
    " que contiene la etiqueta de verdad fundamental"
   ],
   "id": "9b48236b4916880e"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "- Utilice el criterio que haya definido para calcular el valor de la pérdida con respecto a las predicciones y los valores objetivo.\n",
    "- Calcular los gradientes de la pérdida de entropía cruzada.\n",
    "- Muestra los gradientes de los tensores de peso y sesgo, en ese orden."
   ],
   "id": "91aa6471abf22a24"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-12T22:28:46.812702Z",
     "start_time": "2024-06-12T22:28:46.806038Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# Define los tensores.\n",
    "# Los parámetros 'weight' y 'bias' se definen con requires_grad=True, \n",
    "# lo que significa que PyTorch guardará las operaciones en estos tensores \n",
    "# para calcular los gradientes más tarde.\n",
    "weight = torch.rand(2, 4, requires_grad=True)  # weights de 2x4\n",
    "bias = torch.rand(2, requires_grad=True)  # bias de 2\n",
    "\n",
    "# El tensor de 'preds' también debería tener requires_grad=True. \n",
    "# Así, cuando se utiliza para calcular 'loss', PyTorch podrá \n",
    "# calcular el gradiente de 'loss' con respecto a 'preds'.\n",
    "preds = torch.rand(2, 4, requires_grad=True)  # predicciones de 2x4\n",
    "\n",
    "target = torch.tensor([2, 3])  # objetivo de un solo elemento codificado de 2 y 3\n",
    "\n",
    "# Define la función de pérdida de entropía cruzada (CrossEntropyLoss).\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Calcula la pérdida (loss).\n",
    "loss = criterion(preds, target)\n",
    "\n",
    "# A medida que llamamos .backward() en la pérdida (loss), \n",
    "# PyTorch calculará automáticamente los gradientes de 'loss' con respecto a los tensores \n",
    "# que tienen requires_grad=True (en este caso, 'weight', 'bias' y 'preds').\n",
    "loss.backward()\n",
    "\n",
    "# Muestra los gradientes de los tensores 'weight' y 'bias'.\n",
    "print(weight.grad)\n",
    "print(bias.grad)\n",
    "\n",
    "# Nota: No puedes ver el gradiente de 'preds' porque se trata de un tensor intermedio \n",
    "# (en el sentido de que está involucrado en el cálculo de 'loss'), y los gradientes \n",
    "# para los tensores intermedios no se guardan para ahorrar memoria."
   ],
   "id": "78ef42e5c3d8af1b",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "None\n"
     ]
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Acceso a los parámetros del modelo\n",
    "Un modelo PyTorch creado con el nn.Sequential() es un módulo que contiene las diferentes capas de su red. Recordemos que se puede acceder a cada parámetro de capa indexando directamente el modelo creado. En este ejercicio, practicarás el acceso a los parámetros de diferentes capas lineales de una red neuronal. No accederás al sigmoide.\n",
    "\n",
    "Instrucciones\n",
    "100 XP\n",
    "Accede al parámetro weight de la primera capa lineal.\n",
    "Accede al parámetro bias de la segunda capa lineal."
   ],
   "id": "1729c30625cc58cf"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-12T22:46:34.533041Z",
     "start_time": "2024-06-12T22:46:34.471539Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "model = nn.Sequential(nn.Linear(16, 8),\n",
    "                      nn.Sigmoid(),\n",
    "                      nn.Linear(8, 2))\n",
    "\n",
    "# Access the weight of the first linear layer\n",
    "weight_0 = model[0].weight\n",
    "\n",
    "# Access the bias of the second linear layer\n",
    "bias_1 = model[2].bias\n",
    "\n",
    "print(weight_0)\n",
    "print(bias_1)"
   ],
   "id": "92ee64c40ad89b1f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[ 0.2233,  0.2089, -0.1757,  0.1234,  0.1615, -0.1095,  0.0784,  0.2470,\n",
      "         -0.1053,  0.2357,  0.2137, -0.0495,  0.2257, -0.1839, -0.0643,  0.2374],\n",
      "        [-0.2297, -0.1729, -0.1553,  0.2140,  0.0747, -0.1194, -0.2118,  0.0159,\n",
      "         -0.0649,  0.0995,  0.1358, -0.0726, -0.0249, -0.0854,  0.1634, -0.0169],\n",
      "        [-0.1782, -0.1411,  0.1799,  0.0742,  0.0214, -0.1020, -0.1133,  0.2131,\n",
      "         -0.1063,  0.2364, -0.1799,  0.1935, -0.1193,  0.2184,  0.0948, -0.1380],\n",
      "        [-0.2302, -0.1329,  0.1235,  0.0170, -0.0938, -0.0249,  0.2418, -0.1785,\n",
      "         -0.1833,  0.0470, -0.1415, -0.2031, -0.0072, -0.0127, -0.1381, -0.0972],\n",
      "        [-0.0969,  0.2411, -0.2131, -0.1970,  0.1279, -0.1329,  0.0383, -0.0133,\n",
      "         -0.0701, -0.2158, -0.2228, -0.2009, -0.1945, -0.1024,  0.1052,  0.0956],\n",
      "        [-0.2003,  0.2118,  0.0910,  0.0037, -0.2167,  0.0317, -0.1165, -0.1091,\n",
      "         -0.0993,  0.0764,  0.0278, -0.1559,  0.0069,  0.0058,  0.1457,  0.2320],\n",
      "        [-0.1119,  0.1303, -0.0794, -0.0711,  0.2370,  0.2202, -0.1874, -0.2442,\n",
      "         -0.2276, -0.1546,  0.0565, -0.0241,  0.2359,  0.0309, -0.0517,  0.0313],\n",
      "        [-0.0756,  0.0918, -0.0161, -0.0368, -0.0891, -0.0138,  0.2188,  0.2290,\n",
      "         -0.0605,  0.0110, -0.2178, -0.0779,  0.0064,  0.0266, -0.0114,  0.0759]],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-0.1967,  0.2700], requires_grad=True)\n"
     ]
    }
   ],
   "execution_count": 15
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Crea las variables de gradiente accediendo a los gradientes locales de cada tensor de peso.",
   "id": "4a57d685f2e77d7c"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-12T22:51:07.424178Z",
     "start_time": "2024-06-12T22:51:07.348448Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "model = nn.Sequential(nn.Linear(16, 8),\n",
    "                        nn.Sigmoid(),\n",
    "                        nn.Linear(8, 2))\n",
    "\n",
    "# Access the weight of the first linear layer\n",
    "weight0 = model[0].weight\n",
    "weight1 = model[1].weight\n",
    "weight2 = model[2].weight\n",
    "\n",
    "# Access the gradients of the weight of each linear layer\n",
    "grads0 = weight0.grad\n",
    "grads1 = weight1.grad\n",
    "grads2 = weight2.grad\n",
    "\n",
    "print(grads0)\n",
    "print(grads1)\n",
    "print(grads2)"
   ],
   "id": "24188191e5483c40",
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Sigmoid' object has no attribute 'weight'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mAttributeError\u001B[0m                            Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[16], line 10\u001B[0m\n\u001B[1;32m      8\u001B[0m \u001B[38;5;66;03m# Access the weight of the first linear layer\u001B[39;00m\n\u001B[1;32m      9\u001B[0m weight0 \u001B[38;5;241m=\u001B[39m model[\u001B[38;5;241m0\u001B[39m]\u001B[38;5;241m.\u001B[39mweight\n\u001B[0;32m---> 10\u001B[0m weight1 \u001B[38;5;241m=\u001B[39m \u001B[43mmodel\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m]\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mweight\u001B[49m\n\u001B[1;32m     11\u001B[0m weight2 \u001B[38;5;241m=\u001B[39m model[\u001B[38;5;241m2\u001B[39m]\u001B[38;5;241m.\u001B[39mweight\n\u001B[1;32m     13\u001B[0m \u001B[38;5;66;03m# Access the gradients of the weight of each linear layer\u001B[39;00m\n",
      "File \u001B[0;32m~/Library/Caches/pypoetry/virtualenvs/developllms-5obTymQT-py3.12/lib/python3.12/site-packages/torch/nn/modules/module.py:1709\u001B[0m, in \u001B[0;36mModule.__getattr__\u001B[0;34m(self, name)\u001B[0m\n\u001B[1;32m   1707\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m name \u001B[38;5;129;01min\u001B[39;00m modules:\n\u001B[1;32m   1708\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m modules[name]\n\u001B[0;32m-> 1709\u001B[0m \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mAttributeError\u001B[39;00m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mtype\u001B[39m(\u001B[38;5;28mself\u001B[39m)\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__name__\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m object has no attribute \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mname\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "\u001B[0;31mAttributeError\u001B[0m: 'Sigmoid' object has no attribute 'weight'"
     ]
    }
   ],
   "execution_count": 16
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Actualiza los pesos utilizando los gradientes escalados por la tasa de aprendizaje.",
   "id": "ad68b61c347ab420"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-12T22:56:00.650339Z",
     "start_time": "2024-06-12T22:56:00.586756Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "model = nn.Sequential(nn.Linear(16, 8),\n",
    "                        nn.Sigmoid(),\n",
    "                        nn.Linear(8, 2))\n",
    "\n",
    "# Access the weight of the first linear layer\n",
    "weight0 = model[0].weight\n",
    "weight1 = model[1].weight\n",
    "weight2 = model[2].weight\n",
    "\n",
    "# Access the gradients of the weight of each linear layer\n",
    "grads0 = weight0.grad\n",
    "grads1 = weight1.grad\n",
    "grads2 = weight2.grad\n",
    "\n",
    "# Update the weights using the gradients and a learning rate\n",
    "learning_rate = 0.1\n",
    "weight0.data = weight0.data - learning_rate * grads0\n",
    "weight1.data = weight1.data - learning_rate * grads1\n",
    "weight2.data = weight2.data - learning_rate * grads2\n",
    "\n",
    "print(weight0)\n",
    "print(weight1)\n",
    "print(weight2)"
   ],
   "id": "408f1add15a874f1",
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Sigmoid' object has no attribute 'weight'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mAttributeError\u001B[0m                            Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[17], line 10\u001B[0m\n\u001B[1;32m      8\u001B[0m \u001B[38;5;66;03m# Access the weight of the first linear layer\u001B[39;00m\n\u001B[1;32m      9\u001B[0m weight0 \u001B[38;5;241m=\u001B[39m model[\u001B[38;5;241m0\u001B[39m]\u001B[38;5;241m.\u001B[39mweight\n\u001B[0;32m---> 10\u001B[0m weight1 \u001B[38;5;241m=\u001B[39m \u001B[43mmodel\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m]\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mweight\u001B[49m\n\u001B[1;32m     11\u001B[0m weight2 \u001B[38;5;241m=\u001B[39m model[\u001B[38;5;241m2\u001B[39m]\u001B[38;5;241m.\u001B[39mweight\n\u001B[1;32m     13\u001B[0m \u001B[38;5;66;03m# Access the gradients of the weight of each linear layer\u001B[39;00m\n",
      "File \u001B[0;32m~/Library/Caches/pypoetry/virtualenvs/developllms-5obTymQT-py3.12/lib/python3.12/site-packages/torch/nn/modules/module.py:1709\u001B[0m, in \u001B[0;36mModule.__getattr__\u001B[0;34m(self, name)\u001B[0m\n\u001B[1;32m   1707\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m name \u001B[38;5;129;01min\u001B[39;00m modules:\n\u001B[1;32m   1708\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m modules[name]\n\u001B[0;32m-> 1709\u001B[0m \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mAttributeError\u001B[39;00m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mtype\u001B[39m(\u001B[38;5;28mself\u001B[39m)\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__name__\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m object has no attribute \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mname\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "\u001B[0;31mAttributeError\u001B[0m: 'Sigmoid' object has no attribute 'weight'"
     ]
    }
   ],
   "execution_count": 17
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Uso del optimizador PyTorch\n",
    "En el ejercicio anterior, actualizaste manualmente el peso de una red. Ahora ya sabes lo que pasa bajo el capó, pero este enfoque no es escalable a una red de muchas capas.\n",
    "\n",
    "Afortunadamente, el optimizador PyTorch SGD hace un trabajo similar en un puñado de líneas de código. En este ejercicio, practicarás el último paso para completar el bucle de entrenamiento: actualizar los pesos utilizando un optimizador PyTorch.\n",
    "\n",
    "Se ha creado una red neuronal y se ha proporcionado como variable model. Este modelo se utilizó para ejecutar un pase hacia delante y crear el tensor de predicciones pred. El tensor codificado en un punto se denomina target y la función de pérdida de entropía cruzada se almacena como criterion.\n",
    "\n",
    "torch.optim como optim, y torch.nn como nn ya han sido cargados para usted."
   ],
   "id": "520f4aa51104dbba"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Utilice optim para crear un optimizador SGD con una tasa de aprendizaje de su elección (debe ser menor que uno) para el model proporcionado.",
   "id": "34e28e802af76692"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-12T22:59:39.030375Z",
     "start_time": "2024-06-12T22:59:37.201060Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Create the optimizer\n",
    "\n",
    "import torch.optim as optim\n",
    "\n",
    "model = nn.Sequential(nn.Linear(16, 8),\n",
    "                        nn.Sigmoid(),\n",
    "                        nn.Linear(8, 2))\n",
    "\n",
    "# Create the optimizer\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01)\n",
    "\n",
    "print(optimizer)"
   ],
   "id": "e4cf2c93507cfde8",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SGD (\n",
      "Parameter Group 0\n",
      "    dampening: 0\n",
      "    differentiable: False\n",
      "    foreach: None\n",
      "    fused: None\n",
      "    lr: 0.01\n",
      "    maximize: False\n",
      "    momentum: 0\n",
      "    nesterov: False\n",
      "    weight_decay: 0\n",
      ")\n"
     ]
    }
   ],
   "execution_count": 19
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Actualiza los parámetros del modelo mediante el optimizador.",
   "id": "3dbee5c95b101af2"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-12T23:03:30.240937Z",
     "start_time": "2024-06-12T23:03:30.184070Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Create the optimizer\n",
    "\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "model = nn.Sequential(nn.Linear(16, 8),\n",
    "                        nn.Sigmoid(),\n",
    "                        nn.Linear(8, 2))\n",
    "\n",
    "# Create the optimizer\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.001)\n",
    "\n",
    "# Forward pass\n",
    "input_tensor = torch.Tensor(np.random.rand(1, 16))\n",
    "pred = model(input_tensor)\n",
    "print(pred)\n",
    "\n",
    "# Define the target\n",
    "target = torch.tensor([1])\n",
    "print(target)\n",
    "\n",
    "# Compute the loss\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "loss = criterion(pred, target)\n",
    "loss.backward()\n",
    "\n",
    "# Update the model's parameters using the optimizer\n",
    "optimizer.step()\n",
    "\n",
    "print(model)"
   ],
   "id": "69008f60fd50d820",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.4670,  0.5225]], grad_fn=<AddmmBackward0>)\n",
      "tensor([1])\n",
      "Sequential(\n",
      "  (0): Linear(in_features=16, out_features=8, bias=True)\n",
      "  (1): Sigmoid()\n",
      "  (2): Linear(in_features=8, out_features=2, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "execution_count": 22
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Utilización de MSELoss\n",
    "Recordemos que no podemos utilizar la pérdida de entropía cruzada para problemas de regresión. La pérdida de error cuadrático medio (MSELoss) es una función de pérdida común para los problemas de regresión. En este ejercicio, practicarás el cálculo y la observación de la pérdida utilizando NumPy así como su implementación PyTorch."
   ],
   "id": "a7b66a278dd86b0"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Instrucciones\n",
    "100 XP\n",
    "Calcula el MSELoss utilizando NumPy.\n",
    "Crear una función MSELoss utilizando PyTorch.\n",
    "Convierte y_hat y y a tensores y luego a tipos de datos float, y luego úsalos para calcular MSELoss usando PyTorch como mse_pytorch."
   ],
   "id": "675478790ab5f206"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-12T23:28:21.387560Z",
     "start_time": "2024-06-12T23:28:21.377213Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "\n",
    "# Define los tensores\n",
    "y_hat = np.array([10])  # Cuidado, es un array de un elemento, no un número\n",
    "y = np.array([1])  # Igual con esto\n",
    "\n",
    "# Calcula la pérdida MSE usando NumPy\n",
    "mse_numpy = np.mean(np.square(y_hat - y))\n",
    "\n",
    "# Crea la función MSELoss\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "# Calcula la pérdida MSE usando la función de pérdida creada\n",
    "mse_pytorch = criterion(torch.tensor(y_hat).float(), torch.tensor(y).float())\n",
    "\n",
    "print(mse_pytorch)"
   ],
   "id": "cda79ed30d213fc0",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(81.)\n"
     ]
    }
   ],
   "execution_count": 24
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Escribir un bucle de entrenamiento\n",
    "En scikit-learn, todo el bucle de entrenamiento está contenido en el método .fit(). En PyTorch, sin embargo, el bucle se implementa manualmente. Aunque esto proporciona control sobre el contenido del bucle, requiere una implementación personalizada.\n",
    "\n",
    "Escribirás un bucle de entrenamiento cada vez que entrenes un modelo de aprendizaje profundo con PyTorch, que practicarás en este ejercicio. La función show_results() proporcionada mostrará una muestra de la verdad sobre el terreno y las predicciones del modelo.\n",
    "\n",
    "Las importaciones de paquetes proporcionadas son: pandas como pd, torch, torch.nn como nn, torch.optim como optim, así como DataLoader y TensorDataset de torch.utils.data.\n",
    "\n",
    "Se han creado las siguientes variables: dataloader model , que contiene la red neuronal; criterion, que contiene la función de pérdida, nn.MSELoss(); optimizer, que contiene el optimizador SGD; y num_epochs, que contiene el número de épocas."
   ],
   "id": "89c7bc9b5e9d4134"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Escriba un bucle for que itere sobre dataloader; esto debería estar anidado dentro de un bucle for que itere sobre un rango igual al número de épocas.\n",
    "Poner a cero los gradientes del optimizador."
   ],
   "id": "e625d908412891f4"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "columnas: ph,Hardness,Solids,Chloramines,Sulfate,Conductivity,Organic_carbon,Trihalomethanes,Turbidity,Potability",
   "id": "67d1625aff554cc7"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-12T23:43:04.068012Z",
     "start_time": "2024-06-12T23:43:02.908206Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import pandas as pd\n",
    "\n",
    "# Create the model\n",
    "# Crear el modelo\n",
    "model = nn.Sequential(nn.Linear(9, 8),  # Asigna el número correcto de entradas\n",
    "                      nn.Sigmoid(),\n",
    "                      nn.Linear(8, 1))\n",
    "\n",
    "# Create the data loader\n",
    "data = pd.read_csv('/Users/adrianinfantes/Desktop/AIR/CollegeStudies/MachineLearningPath/DataCamp/DevelopLLMs/data/water_potability.csv')\n",
    "X = torch.Tensor(data[['ph', 'Hardness', 'Solids', 'Chloramines', 'Sulfate', 'Conductivity', 'Organic_carbon', 'Trihalomethanes', 'Turbidity']].values)\n",
    "y = torch.Tensor(data['Potability'].values)\n",
    "dataset = TensorDataset(X, y)\n",
    "dataloader = DataLoader(dataset, batch_size=1)\n",
    "\n",
    "# Create the optimizer\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01)\n",
    "\n",
    "# Create the loss function\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "# Define the number of epochs\n",
    "num_epochs = 5\n",
    "\n",
    "# Define the function to show the results\n",
    "def show_results():\n",
    "    for data, target in dataloader:\n",
    "        print(f'Model prediction: {model(data)}')\n",
    "        print(f'True target: {target}')\n",
    "        print(f'Loss: {criterion(model(data), target)}')\n",
    "        break\n",
    "        \n",
    "# Loop over the number of epochs and then the dataloader\n",
    "for epoch in range(num_epochs):\n",
    "    for data, target in dataloader:\n",
    "        # Zero the gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Perform the forward pass\n",
    "        output = model(data)\n",
    "\n",
    "        # Calculate the loss\n",
    "        loss = criterion(output, target)\n",
    "\n",
    "        # Perform the backward pass\n",
    "        loss.backward()\n",
    "\n",
    "        # Update the weights\n",
    "        optimizer.step()\n",
    "\n",
    "# Show the results\n",
    "show_results()"
   ],
   "id": "2d1242b796c4acaf",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/adrianinfantes/Library/Caches/pypoetry/virtualenvs/developllms-5obTymQT-py3.12/lib/python3.12/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([1, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model prediction: tensor([[1.0008]], grad_fn=<AddmmBackward0>)\n",
      "True target: tensor([0.])\n",
      "Loss: 1.0015286207199097\n"
     ]
    }
   ],
   "execution_count": 32
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Escribe el pase hacia delante.\n",
    "Calcule el valor de pérdida MSE utilizando la función criterion() proporcionada.\n",
    "Calcula los gradientes."
   ],
   "id": "a9bfead39816ea31"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-12T23:45:10.477661Z",
     "start_time": "2024-06-12T23:45:09.319357Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import pandas as pd\n",
    "\n",
    "# Create the model\n",
    "model = nn.Sequential(nn.Linear(9, 8),\n",
    "                      nn.Sigmoid(),\n",
    "                      nn.Linear(8, 1))\n",
    "\n",
    "# Create the data loader\n",
    "data = pd.read_csv('/Users/adrianinfantes/Desktop/AIR/CollegeStudies/MachineLearningPath/DataCamp/DevelopLLMs/data/water_potability.csv')\n",
    "\n",
    "X = torch.Tensor(data[['ph', 'Hardness', 'Solids', 'Chloramines', 'Sulfate', 'Conductivity', 'Organic_carbon', 'Trihalomethanes', 'Turbidity']].values)\n",
    "y = torch.Tensor(data['Potability'].values)\n",
    "dataset = TensorDataset(X, y)\n",
    "dataloader = DataLoader(dataset, batch_size=1)\n",
    "\n",
    "# Create the optimizer\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01)\n",
    "\n",
    "# Create the loss function\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "# Define the number of epochs\n",
    "num_epochs = 5\n",
    "\n",
    "# Define the function to show the results\n",
    "def show_results():\n",
    "    for data, target in dataloader:\n",
    "        print(f'Model prediction: {model(data)}')\n",
    "        print(f'True target: {target}')\n",
    "        print(f'Loss: {criterion(model(data), target)}')\n",
    "        break\n",
    "        \n",
    "# Loop over the number of epochs and then the dataloader\n",
    "for epoch in range(num_epochs):\n",
    "    for data, target in dataloader:\n",
    "        # Zero the gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Perform the forward pass\n",
    "        output = model(data)\n",
    "\n",
    "        # Calculate the loss\n",
    "        loss = criterion(output, target)\n",
    "\n",
    "        # Perform the backward pass\n",
    "        loss.backward()\n",
    "\n",
    "        # Update the weights\n",
    "        optimizer.step()\n",
    "        \n",
    "# Show the results\n",
    "show_results()"
   ],
   "id": "48aa9cd93145a6d1",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/adrianinfantes/Library/Caches/pypoetry/virtualenvs/developllms-5obTymQT-py3.12/lib/python3.12/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([1, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model prediction: tensor([[1.0132]], grad_fn=<AddmmBackward0>)\n",
      "True target: tensor([0.])\n",
      "Loss: 1.0266615152359009\n"
     ]
    }
   ],
   "execution_count": 33
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Actualiza los parámetros del modelo.",
   "id": "2e2dec8349bb1709"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-12T23:47:21.603175Z",
     "start_time": "2024-06-12T23:47:20.487196Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import pandas as pd\n",
    "\n",
    "# Create the model\n",
    "model = nn.Sequential(nn.Linear(9, 8),\n",
    "                      nn.Sigmoid(),\n",
    "                      nn.Linear(8, 1))\n",
    "\n",
    "# Create the data loader\n",
    "data = pd.read_csv('/Users/adrianinfantes/Desktop/AIR/CollegeStudies/MachineLearningPath/DataCamp/DevelopLLMs/data/water_potability.csv')\n",
    "\n",
    "X = torch.Tensor(data[['ph', 'Hardness', 'Solids', 'Chloramines', 'Sulfate', 'Conductivity', 'Organic_carbon', 'Trihalomethanes', 'Turbidity']].values)\n",
    "y = torch.Tensor(data['Potability'].values)\n",
    "dataset = TensorDataset(X, y)\n",
    "dataloader = DataLoader(dataset, batch_size=1)\n",
    "\n",
    "# Create the optimizer\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01)\n",
    "\n",
    "# Create the loss function\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "# Define the number of epochs\n",
    "num_epochs = 5\n",
    "\n",
    "# Define the function to show the results\n",
    "def show_results():\n",
    "    for data, target in dataloader:\n",
    "        print(f'Model prediction: {model(data)}')\n",
    "        print(f'True target: {target}')\n",
    "        print(f'Loss: {criterion(model(data), target)}')\n",
    "        break\n",
    "        \n",
    "# Loop over the number of epochs and then the dataloader\n",
    "for epoch in range(num_epochs):\n",
    "    for data, target in dataloader:\n",
    "        # Zero the gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Perform the forward pass\n",
    "        output = model(data)\n",
    "\n",
    "        # Calculate the loss\n",
    "        loss = criterion(output, target)\n",
    "\n",
    "        # Perform the backward pass\n",
    "        loss.backward()\n",
    "\n",
    "        # Update the weights\n",
    "        optimizer.step()\n",
    "        \n",
    "# Show the results\n",
    "show_results()\n",
    "\n",
    "# Print the model's state_dict\n",
    "print(\"Model's state_dict:\")\n",
    "print(model.state_dict())\n",
    "\n",
    "# Print the optimizer's state_dict\n",
    "print(\"Optimizer's state_dict:\")\n",
    "print(optimizer.state_dict())"
   ],
   "id": "8c6274601b4a9ad5",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/adrianinfantes/Library/Caches/pypoetry/virtualenvs/developllms-5obTymQT-py3.12/lib/python3.12/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([1, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model prediction: tensor([[0.9931]], grad_fn=<AddmmBackward0>)\n",
      "True target: tensor([0.])\n",
      "Loss: 0.9862626194953918\n",
      "Model's state_dict:\n",
      "OrderedDict({'0.weight': tensor([[-0.2948, -0.2701, -0.1904,  0.1990,  0.1937,  0.0730,  0.1583, -0.0276,\n",
      "         -0.1629],\n",
      "        [-0.2563, -0.0028, -0.2897, -0.0928, -0.0753, -0.1061, -0.1239, -0.1454,\n",
      "          0.2509],\n",
      "        [ 0.0869, -0.0645, -0.1665, -0.2397, -0.2286,  0.1312, -0.3148, -0.0952,\n",
      "          0.3000],\n",
      "        [ 0.3167,  0.1998,  0.2562, -0.1149, -0.2442, -0.3022,  0.0119,  0.1383,\n",
      "         -0.2991],\n",
      "        [ 0.2925, -0.1858,  0.0978, -0.2465,  0.1586,  0.1445, -0.0873,  0.0350,\n",
      "         -0.0061],\n",
      "        [-0.1940,  0.0958,  0.1679,  0.2697,  0.1861,  0.0699, -0.1951, -0.1864,\n",
      "         -0.1097],\n",
      "        [ 0.0798,  0.1881,  0.3193, -0.1821, -0.3191,  0.2724,  0.0640, -0.1039,\n",
      "          0.3284],\n",
      "        [ 0.1701,  0.0459, -0.0511,  0.0011,  0.2466,  0.0343,  0.2532,  0.0434,\n",
      "          0.0281]]), '0.bias': tensor([-0.3239, -0.2791, -0.3115,  0.1586,  0.0436,  0.2723, -0.1883, -0.3053]), '2.weight': tensor([[ 0.0937,  0.2229, -0.1268,  0.1707, -0.0117,  0.3686,  0.2792,  0.2924]]), '2.bias': tensor([0.3329])})\n",
      "Optimizer's state_dict:\n",
      "{'state': {0: {'momentum_buffer': None}, 1: {'momentum_buffer': None}, 2: {'momentum_buffer': None}, 3: {'momentum_buffer': None}}, 'param_groups': [{'lr': 0.01, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'maximize': False, 'foreach': None, 'differentiable': False, 'fused': None, 'params': [0, 1, 2, 3]}]}\n"
     ]
    }
   ],
   "execution_count": 34
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "41efd132c47cdc0d"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
