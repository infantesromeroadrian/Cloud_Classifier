{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Aplicación de ReLU\n",
    "La función de unidad lineal rectificada (o ReLU) es una de las funciones de activación más comunes en el aprendizaje profundo.\n",
    "\n",
    "Supera los problemas de entrenamiento relacionados con la función sigmoidea aprendida, como el problema de los gradientes evanescentes.\n",
    "\n",
    "En este ejercicio, comenzarás con una implementación de ReLU en PyTorch. A continuación, calcularás los gradientes de la función."
   ],
   "id": "28dc5e5577b5d05"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Instrucciones 1/2\n",
    "50 XP\n",
    "1\n",
    "2\n",
    "Crear una función ReLU en PyTorch."
   ],
   "id": "5e58adb50ab5f3e3"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-13T00:07:38.281373Z",
     "start_time": "2024-06-13T00:07:38.279084Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "\n",
    "relu_pytorch = torch.nn.ReLU()\n",
    "\n",
    "print(relu_pytorch)"
   ],
   "id": "4fa4316df7b5f704",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ReLU()\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Aplicación de ReLU\n",
    "La función de unidad lineal rectificada (o ReLU) es una de las funciones de activación más comunes en el aprendizaje profundo.\n",
    "\n",
    "Supera los problemas de entrenamiento relacionados con la función sigmoidea aprendida, como el problema de los gradientes evanescentes.\n",
    "\n",
    "En este ejercicio, comenzarás con una implementación de ReLU en PyTorch. A continuación, calcularás los gradientes de la función."
   ],
   "id": "fee824676a3c5cc2"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Instrucciones 2/2\n",
    "50 XP\n",
    "2\n",
    "Calcule el gradiente de la función ReLU para x utilizando la función relu_pytorch() que ha definido y, a continuación, ejecute una pasada hacia atrás\n",
    "Hallar el gradiente en x."
   ],
   "id": "497ca0c9e23e02d6"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-13T00:08:48.992052Z",
     "start_time": "2024-06-13T00:08:48.946571Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# Create a ReLU function with PyTorch\n",
    "relu_pytorch = nn.ReLU()\n",
    "\n",
    "# Apply your ReLU function on x, and calculate gradients\n",
    "x = torch.tensor(-1.0, requires_grad=True)\n",
    "y = relu_pytorch(x)\n",
    "y.backward()\n",
    "\n",
    "# Print the gradient of the ReLU function for x\n",
    "gradient = x.grad\n",
    "print(gradient)"
   ],
   "id": "b431f034745c9e03",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.)\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Aplicación de Re con fugasLU\n",
    "Has aprendido que ReLU es una de las funciones de activación más utilizadas en el aprendizaje profundo. Lo encontrará en la arquitectura moderna. Sin embargo, tiene el inconveniente de que los valores de salida son nulos para las entradas negativas y, por lo tanto, los gradientes son nulos. Una vez que un elemento de la entrada es negativo, se pondrá a cero durante el resto del entrenamiento. Leaky ReLU supera este reto utilizando un factor multiplicador para las entradas negativas.\n",
    "\n",
    "En este ejercicio, implementarás la función leaky ReLU en NumPy y PyTorch y practicarás su uso. Ya se han importado los paquetes numpy como np, torch y torch.nn como nn.\n",
    "\n"
   ],
   "id": "9d12f20ae070ca16"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Instrucciones 1/2\n",
    "50 XP\n",
    "1\n",
    "2\n",
    "Cree una función ReLU con fugas en PyTorch con una pendiente negativa de 0,05.\n",
    "Llame a la función en el tensor x, que ya ha sido definido para usted."
   ],
   "id": "e078e0c510e7faca"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-13T00:09:58.145321Z",
     "start_time": "2024-06-13T00:09:58.138201Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Create a leaky relu function in PyTorch\n",
    "leaky_relu_pytorch = nn.LeakyReLU(negative_slope=0.05)\n",
    "\n",
    "x = torch.tensor(-2.0)\n",
    "# Call the above function on the tensor x\n",
    "output = leaky_relu_pytorch(x)\n",
    "print(output)"
   ],
   "id": "a20f7917409bfb5d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(-0.1000)\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Contar el número de parámetros\n",
    "Los modelos de aprendizaje profundo son famosos por tener muchos parámetros. Los modelos lingüísticos recientes tienen miles de millones de parámetros. Con más parámetros viene más complejidad computacional y tiempos de entrenamiento más largos, y un profesional del aprendizaje profundo debe saber cuántos parámetros tiene su modelo.\n",
    "\n",
    "En este ejercicio, calcularás el número de parámetros de tu modelo, primero utilizando PyTorch y después manualmente."
   ],
   "id": "e05da31d22a1de44"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Instrucciones 1/2\n",
    "50 XP\n",
    "1\n",
    "2\n",
    "Iterar a través de los parámetros del modelo para actualizar la variable total con el número total de parámetros del modelo."
   ],
   "id": "aa60b707107c63ee"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-13T00:19:21.222126Z",
     "start_time": "2024-06-13T00:19:21.213526Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# Create a simple model\n",
    "model = nn.Sequential(\n",
    "            nn.Linear(10, 100),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(100, 100),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(100, 1)\n",
    "        )\n",
    "\n",
    "# Initialize the total number of parameters\n",
    "total = 0\n",
    "\n",
    "# Iterate through the model parameters and count them\n",
    "for p in model.parameters():\n",
    "    total += p.numel()\n",
    "    \n",
    "print(total)"
   ],
   "id": "5876e2e1307b0979",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11301\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Manipular la capacidad de una red\n",
    "En este ejercicio, practicarás la creación de redes neuronales con diferentes capacidades. La capacidad de una red refleja el número de parámetros de dicha red. Para ayudarle, se ha implementado una función calculate_capacity(), como se indica a continuación:\n",
    "\n",
    "def calculate_capacity(model):\n",
    "\n",
    "  total = 0\n",
    "\n",
    "  for p in model.parameters():\n",
    "\n",
    "    total += p.numel()\n",
    "\n",
    "  return total\n",
    "Esta función devuelve el número de parámetros de su modelo.\n",
    "\n",
    "El conjunto de datos con el que está entrenando esta red tiene n_features características y n_classes clases. El paquete torch.nn se ha importado como nn."
   ],
   "id": "e90018734106922"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Cree una red neuronal con exactamente tres capas lineales y menos de 120 parámetros, que tome como entradas n_features y como salidas n_classes.",
   "id": "6bf4d1a2a6adb036"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-13T00:25:54.154430Z",
     "start_time": "2024-06-13T00:25:54.144160Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "\n",
    "def calculate_capacity(model):\n",
    "    total = 0\n",
    "    for p in model.parameters():\n",
    "        total += p.numel()\n",
    "    return total\n",
    "\n",
    "# Define the number of features and classes\n",
    "n_features = 8\n",
    "n_classes = 2\n",
    "\n",
    "input_tensor = torch.Tensor([[3, 4, 6, 2, 3, 6, 8, 9]])\n",
    "\n",
    "# Create a neural network with less than 120 parameters\n",
    "model = nn.Sequential(\n",
    "    nn.Linear(n_features, 20),\n",
    "    nn.Linear(20, 12),\n",
    "    nn.Linear(12, 6),\n",
    "    nn.Linear(6, 4),\n",
    "    nn.Softmax(dim=1)\n",
    ")\n",
    "\n",
    "# Forward pass\n",
    "output = model(input_tensor)\n",
    "\n",
    "print(calculate_capacity(model))"
   ],
   "id": "a4d77efbac66c14",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "538\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Cree una red neuronal con exactamente cuatro capas lineales y más de 120 parámetros, que tome como entradas n_features y como salidas n_classes.",
   "id": "f89fba1a5760229b"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-13T00:27:28.775242Z",
     "start_time": "2024-06-13T00:27:28.768256Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "\n",
    "def calculate_capacity(model):\n",
    "    total = 0\n",
    "    for p in model.parameters():\n",
    "        total += p.numel()\n",
    "    return total\n",
    "\n",
    "# Define the number of features and classes\n",
    "n_features = 8\n",
    "n_classes = 2\n",
    "\n",
    "input_tensor = torch.Tensor([[3, 4, 6, 2, 3, 6, 8, 9]])\n",
    "\n",
    "# Create a neural network with more than 120 parameters\n",
    "model = nn.Sequential(\n",
    "    nn.Linear(n_features, 20),\n",
    "    nn.Linear(20, 12),\n",
    "    nn.Linear(12, 20),\n",
    "    nn.Linear(20, 12),\n",
    "    nn.Linear(12, 6),\n",
    "    nn.Linear(6, 4),\n",
    "    nn.Softmax(dim=1)\n",
    ")\n",
    "\n",
    "# Forward pass\n",
    "output = model(input_tensor)\n",
    "\n",
    "print(calculate_capacity(model))"
   ],
   "id": "bb30b67a0f9857ad",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1050\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Experimentar con el ritmo de aprendizaje\n",
    "En este ejercicio, su objetivo es encontrar la tasa de aprendizaje óptima de tal manera que el optimizador pueda encontrar el mínimo de la función no convexa \n",
    " en diez pasos.\n",
    "\n",
    "Experimentará con tres valores diferentes de velocidad de aprendizaje. Para este problema, pruebe valores de tasa de aprendizaje entre 0,001 y 0,1.\n",
    "\n",
    "Se le proporciona la función optimize_and_plot() que toma la tasa de aprendizaje como primer argumento. Esta función ejecutará 10 pasos del optimizador SGD y mostrará los resultados."
   ],
   "id": "fab05d84658a0499"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Pruebe con un valor pequeño de la tasa de aprendizaje, de forma que el optimizador no sea capaz de superar el primer mínimo de la derecha.",
   "id": "6a9b90adf2f37034"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-13T00:32:17.437842Z",
     "start_time": "2024-06-13T00:32:15.661424Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "\n",
    "def optimize_and_plot(learning_rate):\n",
    "    x = torch.tensor([20.0], requires_grad=True)\n",
    "    optimizer = optim.SGD([x], lr=learning_rate)\n",
    "\n",
    "    for _ in range(10):\n",
    "        optimizer.zero_grad()\n",
    "        loss = x**4 - 22*x**3 + 108*x**2 - 128*x\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        print(x)\n",
    "        \n",
    "optimize_and_plot(0.001)"
   ],
   "id": "f90558435f6aa850",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([10.2080], requires_grad=True)\n",
      "tensor([10.7537], requires_grad=True)\n",
      "tensor([11.2169], requires_grad=True)\n",
      "tensor([11.5809], requires_grad=True)\n",
      "tensor([11.8464], requires_grad=True)\n",
      "tensor([12.0279], requires_grad=True)\n",
      "tensor([12.1458], requires_grad=True)\n",
      "tensor([12.2196], requires_grad=True)\n",
      "tensor([12.2648], requires_grad=True)\n",
      "tensor([12.2919], requires_grad=True)\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Pruebe con un valor grande de la tasa de aprendizaje de forma que el optimizador se salte el mínimo global en -2.",
   "id": "e7de1563d212190c"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-13T00:34:10.026055Z",
     "start_time": "2024-06-13T00:34:09.985746Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "\n",
    "def optimize_and_plot(learning_rate):\n",
    "    x = torch.tensor([20.0], requires_grad=True)\n",
    "    optimizer = optim.SGD([x], lr=learning_rate)\n",
    "\n",
    "    for _ in range(10):\n",
    "        optimizer.zero_grad()\n",
    "        loss = x**4 - 22*x**3 + 108*x**2 - 128*x\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        print(x)\n",
    "        \n",
    "optimize_and_plot(0.1)"
   ],
   "id": "26606118d47262b4",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-959.2000], requires_grad=True)\n",
      "tensor([3.5910e+08], requires_grad=True)\n",
      "tensor([-1.8523e+25], requires_grad=True)\n",
      "tensor([inf], requires_grad=True)\n",
      "tensor([nan], requires_grad=True)\n",
      "tensor([nan], requires_grad=True)\n",
      "tensor([nan], requires_grad=True)\n",
      "tensor([nan], requires_grad=True)\n",
      "tensor([nan], requires_grad=True)\n",
      "tensor([nan], requires_grad=True)\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Basándose en los resultados anteriores, pruebe con un valor de tasa de aprendizaje mejor.",
   "id": "8ed53d877b1c089c"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-13T00:36:59.591337Z",
     "start_time": "2024-06-13T00:36:59.572411Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "\n",
    "def optimize_and_plot(learning_rate):\n",
    "    x = torch.tensor([20.0], requires_grad=True)\n",
    "    optimizer = optim.SGD([x], lr=learning_rate)\n",
    "\n",
    "    for _ in range(10):\n",
    "        optimizer.zero_grad()\n",
    "        loss = x**4 - 22*x**3 + 108*x**2 - 128*x\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        print(x)\n",
    "        \n",
    "optimize_and_plot(0.09)"
   ],
   "id": "a0c066c5babeba3b",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-861.2800], requires_grad=True)\n",
      "tensor([2.3443e+08], requires_grad=True)\n",
      "tensor([-4.6379e+24], requires_grad=True)\n",
      "tensor([inf], requires_grad=True)\n",
      "tensor([nan], requires_grad=True)\n",
      "tensor([nan], requires_grad=True)\n",
      "tensor([nan], requires_grad=True)\n",
      "tensor([nan], requires_grad=True)\n",
      "tensor([nan], requires_grad=True)\n",
      "tensor([nan], requires_grad=True)\n"
     ]
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Experimentar con el impulso\n",
    "En este ejercicio, tu objetivo es encontrar el momento óptimo tal que el optimizador pueda encontrar el mínimo de la siguiente función no convexa \n",
    " en 20 pasos. Experimentarás con dos valores de impulso diferentes. Para este problema, la tasa de aprendizaje se fija en 0,01.\n",
    "\n",
    "Se le proporciona la función optimize_and_plot() que toma la tasa de aprendizaje como primer argumento. Esta función ejecutará 20 pasos del optimizador SGD y mostrará los resultados."
   ],
   "id": "b121c987e7cf2f03"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Prueba un primer valor para el impulso tal que el optimizador se atasque en el primer mínimo.",
   "id": "49371d47868ffea2"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-13T00:39:00.070759Z",
     "start_time": "2024-06-13T00:39:00.064123Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "\n",
    "momentum = 0.1\n",
    "optimize_and_plot(momentum)"
   ],
   "id": "cb157f0bb122ae97",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-959.2000], requires_grad=True)\n",
      "tensor([3.5910e+08], requires_grad=True)\n",
      "tensor([-1.8523e+25], requires_grad=True)\n",
      "tensor([inf], requires_grad=True)\n",
      "tensor([nan], requires_grad=True)\n",
      "tensor([nan], requires_grad=True)\n",
      "tensor([nan], requires_grad=True)\n",
      "tensor([nan], requires_grad=True)\n",
      "tensor([nan], requires_grad=True)\n",
      "tensor([nan], requires_grad=True)\n"
     ]
    }
   ],
   "execution_count": 16
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Pruebe un segundo valor para el impulso tal que el optimizador encuentre el óptimo global.",
   "id": "66941a5eb5a4ed0d"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-13T00:39:51.081916Z",
     "start_time": "2024-06-13T00:39:51.069922Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "\n",
    "momentum = 0.9\n",
    "optimize_and_plot(momentum)"
   ],
   "id": "10e3bbd1244938a9",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-8792.7998], requires_grad=True)\n",
      "tensor([2.4519e+12], requires_grad=True)\n",
      "tensor([-5.3064e+37], requires_grad=True)\n",
      "tensor([inf], requires_grad=True)\n",
      "tensor([nan], requires_grad=True)\n",
      "tensor([nan], requires_grad=True)\n",
      "tensor([nan], requires_grad=True)\n",
      "tensor([nan], requires_grad=True)\n",
      "tensor([nan], requires_grad=True)\n",
      "tensor([nan], requires_grad=True)\n"
     ]
    }
   ],
   "execution_count": 17
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    " Congelar capas de un modelo\n",
    "Está a punto de ajustar un modelo en una nueva tarea después de cargar los pesos preentrenados. El modelo contiene tres capas lineales. Sin embargo, como su conjunto de datos es pequeño, sólo desea entrenar la última capa lineal de este modelo y congelar las dos primeras capas lineales.\n",
    "\n",
    "El modelo ya se ha creado y existe en la variable model. Utilizará el método named_parameters del modelo para listar los parámetros del modelo. Cada parámetro se describe mediante un nombre. Este nombre es una cadena con la siguiente convención de nomenclatura: x.name donde x es el índice de la capa.\n",
    "\n",
    "Recuerde que una capa lineal tiene dos parámetros: el weight y el bias."
   ],
   "id": "40e766bf652ec162"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Utilice una sentencia if para determinar si el parámetro debe congelarse o no en función de su nombre.\n",
    "Congela los parámetros de las dos primeras capas de este modelo."
   ],
   "id": "344852fd74054d12"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-13T00:49:32.104682Z",
     "start_time": "2024-06-13T00:49:32.098730Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for name, param in model.named_parameters():    \n",
    "  \n",
    "    # Check if the parameters belong to the first layer\n",
    "    if name == '0.weight' or name == '0.bias':\n",
    "      \n",
    "        # Freeze the parameters\n",
    "        param.requires_grad = False\n",
    "  \n",
    "    # Check if the parameters belong to the second layer\n",
    "    if name == '1.weight' or name == '1.bias':\n",
    "      \n",
    "        # Freeze the parameters\n",
    "        param.requires_grad = False"
   ],
   "id": "303be5ae972066ac",
   "outputs": [],
   "execution_count": 20
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Inicialización de capas\n",
    "La inicialización de los pesos de una red neuronal ha sido el centro de atención de los investigadores durante muchos años. Cuando se entrena una red, el método utilizado para inicializar los pesos tiene un impacto directo en el rendimiento final de la red.\n",
    "\n",
    "Como profesional del aprendizaje automático, debe ser capaz de experimentar con diferentes estrategias de inicialización. En este ejercicio, vas a crear una pequeña red neuronal formada por dos capas y vas a decidir inicializar los pesos de cada capa con el método uniforme."
   ],
   "id": "c8710b191cd52e6b"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Instrucciones\n",
    "100 XP\n",
    "Para cada capa (layer0 y layer1), utilice el método de inicialización uniforme para inicializar los pesos."
   ],
   "id": "a6324e5f9874da4a"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-13T00:50:52.544523Z",
     "start_time": "2024-06-13T00:50:52.540992Z"
    }
   },
   "cell_type": "code",
   "source": [
    "layer0 = nn.Linear(16, 32)\n",
    "layer1 = nn.Linear(32, 64)\n",
    "\n",
    "# Use uniform initialization for layer0 and layer1 weights\n",
    "nn.init.uniform_(layer0.weight)\n",
    "nn.init.uniform_(layer1.weight)\n",
    "\n",
    "model = nn.Sequential(layer0, layer1)\n",
    "\n",
    "print(model)"
   ],
   "id": "df6f2d298a75f865",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential(\n",
      "  (0): Linear(in_features=16, out_features=32, bias=True)\n",
      "  (1): Linear(in_features=32, out_features=64, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "execution_count": 22
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Uso de la clase TensorDataset\n",
    "En la práctica, cargar tus datos en un conjunto de datos PyTorch será uno de los primeros pasos que darás para crear y entrenar una red neuronal con PyTorch.\n",
    "\n",
    "La clase TensorDataset es muy útil cuando su conjunto de datos se puede cargar directamente como una matriz NumPy. Recordemos que TensorDataset() puede tomar una o más matrices NumPy como entrada.\n",
    "\n",
    "En este ejercicio, practicarás la creación de un conjunto de datos PyTorch utilizando la clase TensorDataset.\n",
    "\n",
    "torch y numpy ya han sido importados, junto con la clase TensorDataset.\n",
    "\n",
    "Instrucciones\n",
    "100 XP\n",
    "Convierte las matrices NumPy proporcionadas en tensores PyTorch.\n",
    "Cree un TensorDataset utilizando torch_features y los tensores torch_target proporcionados (en este orden).\n",
    "Devuelve el último elemento del conjunto de datos."
   ],
   "id": "fc3607f0980f0e64"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-13T22:32:09.333820Z",
     "start_time": "2024-06-13T22:32:09.329712Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np  # Importing numpy library\n",
    "import torch  # Importing PyTorch library\n",
    "from torch.utils.data import TensorDataset  # Importing TensorDataset from PyTorch\n",
    "\n",
    "np_features = np.array(np.random.rand(12, 8))  # Creating a 2D array with random numbers\n",
    "np_target = np.array(np.random.rand(12, 1))  # Creating another 2D array with random numbers\n",
    "\n",
    "# Convert numpy arrays to PyTorch tensors\n",
    "torch_features = torch.from_numpy(np_features)\n",
    "torch_target = torch.from_numpy(np_target)\n",
    "\n",
    "# Create a TensorDataset from the tensors\n",
    "dataset = TensorDataset(torch_features, torch_target)\n",
    "\n",
    "# Print the last element of the dataset\n",
    "print(dataset[-1])"
   ],
   "id": "b69f3494a77756ea",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor([0.5655, 0.7144, 0.7414, 0.9860, 0.6539, 0.6737, 0.2035, 0.3294],\n",
      "       dtype=torch.float64), tensor([0.3986], dtype=torch.float64))\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "De la carga de datos a la ejecución de un pase de avance\n",
    "En este ejercicio, crearás un PyTorch DataLoader a partir de un pandas DataFrame y llamarás a un modelo sobre este conjunto de datos. En concreto, ejecutará un pase hacia adelante en una red neuronal. Seguirás trabajando con redes neuronales totalmente conectadas, como has hecho hasta ahora.\n",
    "\n",
    "Empezarás subconjuntando un DataFrame cargado llamado dataframe, convirtiendo características y objetivos en arrays NumPy, y convirtiendo a tensores PyTorch para crear un conjunto de datos PyTorch.\n",
    "\n",
    "Este conjunto de datos puede cargarse en PyTorch DataLoader, procesarse por lotes, barajarse y utilizarse para ejecutar un pase hacia delante en una red neuronal totalmente conectada personalizada.\n",
    "\n",
    "NumPy como np, pandas como pd, torch, TensorDataset(), y DataLoader() han sido importados para usted.\n",
    "\n",
    "Instrucciones 1/3\n",
    "35 XP\n",
    "1\n",
    "2\n",
    "3\n",
    "Extraiga los valores de las características (ph, Sulfate, Conductivity, Organic_carbon) y de los objetivos (Potability) y cárguelos en los tensores adecuados para representar las características y los objetivos.\n",
    "Usa ambos tensores para crear un conjunto de datos PyTorch usando la clase dataset que es más rápida de usar cuando los tensores no requieren ningún preprocesamiento adicional."
   ],
   "id": "5c9c332a139c1293"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-13T22:33:45.514854Z",
     "start_time": "2024-06-13T22:33:45.501266Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "# Load the dataframe\n",
    "\n",
    "dataframe = pd.read_csv('/Users/adrianinfantes/Desktop/AIR/CollegeStudies/MachineLearningPath/DataCamp/DevelopLLMs/data/water_potability.csv')\n",
    "\n",
    "# Extract the features and targets\n",
    "# Load the different columns into two PyTorch tensors\n",
    "features = torch.tensor(dataframe[['ph', 'Sulfate', 'Conductivity', 'Organic_carbon']].values).float()\n",
    "target = torch.tensor(dataframe['Potability'].values).float()\n",
    "\n",
    "# Create a dataset from the two generated tensors\n",
    "dataset = TensorDataset(features, target)\n",
    "\n",
    "print(dataset)"
   ],
   "id": "7a68f2823b6db70a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<torch.utils.data.dataset.TensorDataset object at 0x132515550>\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Cree un PyTorch DataLoader a partir del TensorDataset creado; este DataLoader debe utilizar un batch_size de dos y shuffle el conjunto de datos.",
   "id": "19695cf7787b0862"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-13T22:34:49.655177Z",
     "start_time": "2024-06-13T22:34:49.641551Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "# Load the dataframe\n",
    "\n",
    "dataframe = pd.read_csv('/Users/adrianinfantes/Desktop/AIR/CollegeStudies/MachineLearningPath/DataCamp/DevelopLLMs/data/water_potability.csv')\n",
    "\n",
    "# Extract the features and targets\n",
    "# Load the different columns into two PyTorch tensors\n",
    "features = torch.tensor(dataframe[['ph', 'Sulfate', 'Conductivity', 'Organic_carbon']].values).float()\n",
    "target = torch.tensor(dataframe['Potability'].values).float()\n",
    "\n",
    "# Create a dataset from the two generated tensors\n",
    "dataset = TensorDataset(features, target)\n",
    "\n",
    "# Create a DataLoader from the created dataset\n",
    "dataloader = DataLoader(dataset, batch_size=2, shuffle=True)\n",
    "x, y = next(iter(dataloader))\n",
    "print(x, y)"
   ],
   "id": "4408b93cd946d548",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.4026, 0.4098, 0.4784, 0.2341],\n",
      "        [0.6264, 0.7577, 0.4812, 0.3327]]) tensor([1., 0.])\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Implemente una pequeña red neuronal totalmente conectada utilizando exactamente dos capas lineales y la dirección nn.Sequential() API, donde el tamaño final de la salida es 1.",
   "id": "2f09c00e54f195b7"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-13T22:36:18.566488Z",
     "start_time": "2024-06-13T22:36:18.552791Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import torch.nn as nn\n",
    "\n",
    "# Load the dataframe\n",
    "\n",
    "dataframe = pd.read_csv('/Users/adrianinfantes/Desktop/AIR/CollegeStudies/MachineLearningPath/DataCamp/DevelopLLMs/data/water_potability.csv')\n",
    "\n",
    "# Extract the features and targets\n",
    "# Load the different columns into two PyTorch tensors\n",
    "features = torch.tensor(dataframe[['ph', 'Sulfate', 'Conductivity', 'Organic_carbon']].values).float()\n",
    "target = torch.tensor(dataframe['Potability'].values).float()\n",
    "\n",
    "# Create a dataset from the two generated tensors\n",
    "dataset = TensorDataset(features, target)\n",
    "\n",
    "# Create a DataLoader from the created dataset\n",
    "dataloader = DataLoader(dataset, batch_size=2, shuffle=True)\n",
    "x, y = next(iter(dataloader))\n",
    "\n",
    "# Create a fully connected network with two layers\n",
    "\n",
    "model = nn.Sequential(\n",
    "    nn.Linear(4, 8),\n",
    "    nn.Linear(8, 1)\n",
    ")\n",
    "output = model(features)\n",
    "print(output)"
   ],
   "id": "33973cd04e7ab8bc",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.3259],\n",
      "        [-0.3362],\n",
      "        [-0.3469],\n",
      "        ...,\n",
      "        [-0.2855],\n",
      "        [-0.3753],\n",
      "        [-0.4132]], grad_fn=<AddmmBackward0>)\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Escribir el bucle de evaluación\n",
    "En este ejercicio, practicarás escribiendo el bucle de evaluación. Recuerde que el bucle de evaluación es similar al bucle de entrenamiento, salvo que no realizará el cálculo del gradiente ni el paso del optimizador.\n",
    "\n",
    "El model ya ha sido definido para usted, junto con el objeto validationloader, que es un conjunto de datos.\n",
    "\n",
    "Instrucciones 1/2\n",
    "50 XP\n",
    "1\n",
    "2\n",
    "Ponga el modelo en modo de evaluación.\n",
    "Suma la pérdida del lote actual a la variable validation_loss."
   ],
   "id": "a20e77101a3e3de5"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-13T22:54:41.061951Z",
     "start_time": "2024-06-13T22:54:39.094629Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "# Load the dataframe\n",
    "dataframe = pd.read_csv('/Users/adrianinfantes/Desktop/AIR/CollegeStudies/MachineLearningPath/DataCamp/DevelopLLMs/data/water_potability.csv')\n",
    "\n",
    "# Extract the features and targets\n",
    "# Load the different columns into two PyTorch tensors\n",
    "features = torch.tensor(dataframe[['ph', 'Sulfate', 'Conductivity', 'Organic_carbon']].values).float()\n",
    "target = torch.tensor(dataframe['Potability'].values).float()\n",
    "\n",
    "# Create a dataset from the two generated tensors\n",
    "dataset = TensorDataset(features, target)\n",
    "\n",
    "# Create a DataLoader from the created dataset\n",
    "dataloader = DataLoader(dataset, batch_size=2, shuffle=True)\n",
    "x, y = next(iter(dataloader))\n",
    "\n",
    "# Create a fully connected network with two layers\n",
    "model = nn.Sequential(\n",
    "    nn.Linear(4, 8),\n",
    "    nn.Linear(8, 1)\n",
    ")\n",
    "\n",
    "# Put the model in evaluation mode\n",
    "model.eval()\n",
    "\n",
    "# Initialize the loss function\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "\n",
    "# Initialize the optimizer\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
    "\n",
    "# Initialize the validation loss\n",
    "validation_loss = 0.0\n",
    "\n",
    "# Iterate over the validation loader\n",
    "for x, y in dataloader:\n",
    "    # Forward pass\n",
    "    output = model(x)\n",
    "    \n",
    "    # Compute the validation loss\n",
    "    loss = criterion(output, y.unsqueeze(1))\n",
    "    validation_loss += loss.item()\n",
    "    \n",
    "print(validation_loss)"
   ],
   "id": "cfddc45a12c830f5",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "699.92709004879\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Calcular el valor medio de pérdida de la época.\n",
    "Vuelve a poner el modelo en modo de entrenamiento."
   ],
   "id": "da18765f8c19cb40"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-13T22:57:04.124374Z",
     "start_time": "2024-06-13T22:57:04.009300Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Initialize the loss function\n",
    "\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "\n",
    "# Initialize the optimizer\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
    "\n",
    "# Initialize the validation loss\n",
    "validation_loss = 0.0\n",
    "\n",
    "# Iterate over the validation loader\n",
    "for x, y in dataloader:\n",
    "    # Forward pass\n",
    "    output = model(x)\n",
    "    \n",
    "    # Compute the validation loss\n",
    "    loss = criterion(output, y.unsqueeze(1))\n",
    "    validation_loss += loss.item()\n",
    "    \n",
    "# Compute the average validation loss\n",
    "validation_loss /= len(dataloader)\n",
    "print(validation_loss)\n",
    "\n",
    "# Put the model back in training mode\n",
    "model.train()"
   ],
   "id": "4f80708e1a2b0895",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6957360357342373\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Linear(in_features=4, out_features=8, bias=True)\n",
       "  (1): Linear(in_features=8, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Cálculo de la precisión mediante torchmetrics\n",
    "Además de las pérdidas, también debe controlar la precisión durante el entrenamiento. De este modo, podrá seleccionar la época en la que el modelo obtuvo los mejores resultados.\n",
    "\n",
    "En este ejercicio, practicará el uso del paquete torchmetrics para calcular la precisión. Utilizará una muestra del conjunto de datos de máscaras faciales. Este conjunto de datos contiene tres clases diferentes. La función plot_errors mostrará las muestras en las que las predicciones del modelo no coincidan con la verdad sobre el terreno. Realizar este análisis de errores le ayudará a comprender los modos de fallo de su modelo.\n",
    "\n",
    "El paquete torchmetrics ya está importado. El modelo outputs son las probabilidades devueltas por un softmax como último paso del modelo. El tensor labels contiene las etiquetas como vectores codificados de un solo golpe.\n",
    "\n",
    "Instrucciones 1/2\n",
    "50 XP\n",
    "1\n",
    "2\n",
    "Cree una métrica de precisión para un problema \"multiclass\" con tres clases.\n",
    "Calcular la precisión de cada lote del cargador de datos."
   ],
   "id": "ba0289f0856905f3"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-13T23:01:53.028919Z",
     "start_time": "2024-06-13T23:01:52.878839Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Import torchmetrics\n",
    "from torchmetrics import Accuracy\n",
    "\n",
    "# Initialize the accuracy metric\n",
    "accuracy = Accuracy('multiclass', num_classes=3)  # Para tareas de clasificación multiclase con tres clases\n",
    "\n",
    "# Initialize the validation loss\n",
    "validation_loss = 0.0\n",
    "\n",
    "# Iterate over the validation loader\n",
    "for x, y in dataloader:\n",
    "    # Forward pass\n",
    "    output = model(x)\n",
    "\n",
    "    # Compute the validation loss\n",
    "    loss = criterion(output, y.unsqueeze(1))\n",
    "    validation_loss += loss.item()\n",
    "\n",
    "    # Compute the accuracy\n",
    "    acc = accuracy(output, y)\n",
    "    print(acc)\n",
    "\n",
    "# Compute the average validation loss\n",
    "validation_loss /= len(dataloader)\n",
    "print(validation_loss)\n",
    "\n",
    "# Put the model back in training mode\n",
    "model.train()"
   ],
   "id": "e5f7a8f76c22dfe7",
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "If `preds` have one dimension more than `target`, `preds.shape[1]` should be equal to number of classes.",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[13], line 20\u001B[0m\n\u001B[1;32m     17\u001B[0m     validation_loss \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m loss\u001B[38;5;241m.\u001B[39mitem()\n\u001B[1;32m     19\u001B[0m     \u001B[38;5;66;03m# Compute the accuracy\u001B[39;00m\n\u001B[0;32m---> 20\u001B[0m     acc \u001B[38;5;241m=\u001B[39m \u001B[43maccuracy\u001B[49m\u001B[43m(\u001B[49m\u001B[43moutput\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     21\u001B[0m     \u001B[38;5;28mprint\u001B[39m(acc)\n\u001B[1;32m     23\u001B[0m \u001B[38;5;66;03m# Compute the average validation loss\u001B[39;00m\n",
      "File \u001B[0;32m~/Library/Caches/pypoetry/virtualenvs/developllms-5obTymQT-py3.12/lib/python3.12/site-packages/torch/nn/modules/module.py:1532\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1530\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[1;32m   1531\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 1532\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Library/Caches/pypoetry/virtualenvs/developllms-5obTymQT-py3.12/lib/python3.12/site-packages/torch/nn/modules/module.py:1541\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1536\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1537\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1538\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[1;32m   1539\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1540\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1541\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1543\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m   1544\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[0;32m~/Library/Caches/pypoetry/virtualenvs/developllms-5obTymQT-py3.12/lib/python3.12/site-packages/torchmetrics/metric.py:311\u001B[0m, in \u001B[0;36mMetric.forward\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m    309\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_cache \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_full_state_update(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[1;32m    310\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m--> 311\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_cache \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_forward_reduce_state_update\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    313\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_cache\n",
      "File \u001B[0;32m~/Library/Caches/pypoetry/virtualenvs/developllms-5obTymQT-py3.12/lib/python3.12/site-packages/torchmetrics/metric.py:380\u001B[0m, in \u001B[0;36mMetric._forward_reduce_state_update\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m    377\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_enable_grad \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m  \u001B[38;5;66;03m# allow grads for batch computation\u001B[39;00m\n\u001B[1;32m    379\u001B[0m \u001B[38;5;66;03m# calculate batch state and compute batch value\u001B[39;00m\n\u001B[0;32m--> 380\u001B[0m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mupdate\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    381\u001B[0m batch_val \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcompute()\n\u001B[1;32m    383\u001B[0m \u001B[38;5;66;03m# reduce batch and global state\u001B[39;00m\n",
      "File \u001B[0;32m~/Library/Caches/pypoetry/virtualenvs/developllms-5obTymQT-py3.12/lib/python3.12/site-packages/torchmetrics/metric.py:482\u001B[0m, in \u001B[0;36mMetric._wrap_update.<locals>.wrapped_func\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    480\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m torch\u001B[38;5;241m.\u001B[39mset_grad_enabled(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_enable_grad):\n\u001B[1;32m    481\u001B[0m     \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 482\u001B[0m         \u001B[43mupdate\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    483\u001B[0m     \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mRuntimeError\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m err:\n\u001B[1;32m    484\u001B[0m         \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mExpected all tensors to be on\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mstr\u001B[39m(err):\n",
      "File \u001B[0;32m~/Library/Caches/pypoetry/virtualenvs/developllms-5obTymQT-py3.12/lib/python3.12/site-packages/torchmetrics/classification/stat_scores.py:339\u001B[0m, in \u001B[0;36mMulticlassStatScores.update\u001B[0;34m(self, preds, target)\u001B[0m\n\u001B[1;32m    337\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"Update state with predictions and targets.\"\"\"\u001B[39;00m\n\u001B[1;32m    338\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mvalidate_args:\n\u001B[0;32m--> 339\u001B[0m     \u001B[43m_multiclass_stat_scores_tensor_validation\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    340\u001B[0m \u001B[43m        \u001B[49m\u001B[43mpreds\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtarget\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mnum_classes\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmultidim_average\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mignore_index\u001B[49m\n\u001B[1;32m    341\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    342\u001B[0m preds, target \u001B[38;5;241m=\u001B[39m _multiclass_stat_scores_format(preds, target, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtop_k)\n\u001B[1;32m    343\u001B[0m tp, fp, tn, fn \u001B[38;5;241m=\u001B[39m _multiclass_stat_scores_update(\n\u001B[1;32m    344\u001B[0m     preds, target, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mnum_classes, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtop_k, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39maverage, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmultidim_average, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mignore_index\n\u001B[1;32m    345\u001B[0m )\n",
      "File \u001B[0;32m~/Library/Caches/pypoetry/virtualenvs/developllms-5obTymQT-py3.12/lib/python3.12/site-packages/torchmetrics/functional/classification/stat_scores.py:283\u001B[0m, in \u001B[0;36m_multiclass_stat_scores_tensor_validation\u001B[0;34m(preds, target, num_classes, multidim_average, ignore_index)\u001B[0m\n\u001B[1;32m    281\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mIf `preds` have one dimension more than `target`, `preds` should be a float tensor.\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m    282\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m preds\u001B[38;5;241m.\u001B[39mshape[\u001B[38;5;241m1\u001B[39m] \u001B[38;5;241m!=\u001B[39m num_classes:\n\u001B[0;32m--> 283\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[1;32m    284\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mIf `preds` have one dimension more than `target`, `preds.shape[1]` should be\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    285\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m equal to number of classes.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    286\u001B[0m     )\n\u001B[1;32m    287\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m preds\u001B[38;5;241m.\u001B[39mshape[\u001B[38;5;241m2\u001B[39m:] \u001B[38;5;241m!=\u001B[39m target\u001B[38;5;241m.\u001B[39mshape[\u001B[38;5;241m1\u001B[39m:]:\n\u001B[1;32m    288\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[1;32m    289\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mIf `preds` have one dimension more than `target`, the shape of `preds` should be\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    290\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m (N, C, ...), and the shape of `target` should be (N, ...).\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    291\u001B[0m     )\n",
      "\u001B[0;31mValueError\u001B[0m: If `preds` have one dimension more than `target`, `preds.shape[1]` should be equal to number of classes."
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Data Augmentation: Aumento de datos\n",
    "\n",
    "El aumento de datos es una técnica comúnmente utilizada para mejorar el rendimiento de los modelos de aprendizaje profundo. Consiste en aplicar transformaciones aleatorias a los datos de entrenamiento, como rotaciones, recortes, reflejos y cambios de color. De esta manera, el modelo puede aprender a generalizar mejor y a ser más robusto a las variaciones en los datos."
   ],
   "id": "2f5d0443308c2be9"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Experimentar con el abandono\n",
    "La capa de exclusión elimina aleatoriamente los elementos del tensor de entrada. Esto ayuda a combatir el sobreajuste. En este ejercicio, crearás una pequeña red neuronal con al menos dos capas lineales, dos capas de abandono y dos funciones de activación.\n",
    "\n",
    "El paquete torch.nn ya se ha importado como nn. Un input_tensor de dimensiones  ha sido creado para usted.\n",
    "\n",
    "Instrucciones 1/2\n",
    "50 XP\n",
    "1\n",
    "Cree una pequeña red neuronal con una capa lineal, una función ReLU y una capa de abandono, en ese orden.\n",
    "El modelo debe tomar input_tensor como entrada y devolver una salida de tamaño 16."
   ],
   "id": "16fd0057f7e9ad8d"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-13T23:12:20.365074Z",
     "start_time": "2024-06-13T23:12:20.351933Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "# Load the dataframe\n",
    "dataframe = pd.read_csv('/Users/adrianinfantes/Desktop/AIR/CollegeStudies/MachineLearningPath/DataCamp/DevelopLLMs/data/water_potability.csv')\n",
    "\n",
    "# Extract the features and targets\n",
    "# Load the different columns into two PyTorch tensors\n",
    "features = torch.tensor(dataframe[['ph', 'Sulfate', 'Conductivity', 'Organic_carbon']].values).float()\n",
    "target = torch.tensor(dataframe['Potability'].values).float()\n",
    "\n",
    "# Create a dataset from the two generated tensors\n",
    "dataset = TensorDataset(features, target)\n",
    "\n",
    "# Create a DataLoader from the created dataset\n",
    "dataloader = DataLoader(dataset, batch_size=2, shuffle=True)\n",
    "x, y = next(iter(dataloader))\n",
    "\n",
    "model = nn.Sequential(\n",
    "    nn.Linear(4, 8), # Capa lineal. 4 entradas, 8 salidas\n",
    "    nn.ReLU(), # Función de activación. Usamos ReLU como función de activación\n",
    "    nn.Dropout(0.2), # Capa de abandono. 20% de abandono\n",
    "    nn.Linear(8, 16) # Capa lineal. 8 entradas, 16 salidas\n",
    ")\n",
    "\n",
    "output = model(features)\n",
    "print(output)"
   ],
   "id": "e505df025ae4191b",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.1605, -0.0954, -0.4332,  ..., -0.3773,  0.0200,  0.1919],\n",
      "        [ 0.0390,  0.0697, -0.3228,  ..., -0.3057, -0.1184,  0.0131],\n",
      "        [-0.1030, -0.0300, -0.4960,  ..., -0.3904, -0.0576,  0.1249],\n",
      "        ...,\n",
      "        [ 0.3275,  0.2047, -0.1405,  ..., -0.3456,  0.0696,  0.1859],\n",
      "        [-0.1550, -0.0499, -0.4954,  ..., -0.3693, -0.0230,  0.1531],\n",
      "        [-0.1478, -0.0639, -0.5449,  ..., -0.2290,  0.0765,  0.0132]],\n",
      "       grad_fn=<AddmmBackward0>)\n"
     ]
    }
   ],
   "execution_count": 18
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Utilizando la misma red neuronal, establezca la probabilidad de poner a cero elementos en la capa de abandono en 0.8.",
   "id": "f31edef86d1480a7"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Create a small neural network\n",
    "\n",
    "model = nn.Sequential(\n",
    "    nn.Linear(4, 8),\n",
    "    nn.ReLU(),\n",
    "    nn.Dropout(0.8),\n",
    "    nn.Linear(8, 16)\n",
    ")\n",
    "\n",
    "output = model(features)\n",
    "print(output)"
   ],
   "id": "61f10925f86bd114"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Aplicación de la búsqueda aleatoria\n",
    "La búsqueda de hiperparámetros es un método costoso desde el punto de vista informático para experimentar con diferentes valores de hiperparámetros. Sin embargo, puede mejorar el rendimiento. En este ejercicio, implementarás un algoritmo de búsqueda aleatoria.\n",
    "\n",
    "Muestreará aleatoriamente 10 valores de la tasa de aprendizaje y el momento a partir de la distribución uniforme. Para ello, utilizará la función np.random.uniform()."
   ],
   "id": "3805ed704d2aa385"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Muestrear aleatoriamente un factor de tasa de aprendizaje entre 2 y 4 para que la tasa de aprendizaje (lr) esté acotada entre  y .\n",
    "Muestre al azar un momento entre 0,85 y 0,99."
   ],
   "id": "b0baa520f8b0804f"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import numpy as np\n",
    "\n",
    "values = []\n",
    "\n",
    "# Sample 10 random values for learning rate and momentum\n",
    "for idx in range(10):\n",
    "    factor = np.random.uniform(2, 4)\n",
    "    lr = 10 ** -factor\n",
    "    \n",
    "    momentum = np.random.uniform(0.85, 0.99)\n",
    "    \n",
    "    values.append((lr, momentum))"
   ],
   "id": "e0a4ea5c4a7d4c63"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
